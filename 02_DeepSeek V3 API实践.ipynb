{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> DeepSeek v3 API实践"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: openai in /root/miniconda3/lib/python3.12/site-packages (1.64.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /root/miniconda3/lib/python3.12/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /root/miniconda3/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /root/miniconda3/lib/python3.12/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /root/miniconda3/lib/python3.12/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /root/miniconda3/lib/python3.12/site-packages (from openai) (1.10.12)\n",
      "Requirement already satisfied: sniffio in /root/miniconda3/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /root/miniconda3/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /root/miniconda3/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /root/miniconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /root/miniconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /root/miniconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /root/miniconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import openai\n",
    "import os\n",
    "\n",
    "## 初始化客户端\n",
    "openai.api_key = \"sk-6fd33eaba5b54e3a9d6f7ff76b2565aa\"\n",
    "\n",
    "openai.api_base= \"https://api.deepseek.com/v1\"\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=openai.api_key ,base_url=openai.api_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 大模型交互方式 1（最常用）\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"deepseek-chat\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"你好!什么是机器学习？\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='f2d1ea5e-bafa-4142-a943-2fbf7219da35', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='你好！机器学习（Machine Learning, ML）是人工智能（AI）的一个子领域，它致力于研究和开发算法和统计模型，使计算机系统能够通过数据“学习”并改进其性能，而无需显式编程。简单来说，机器学习的目标是让计算机从数据中自动发现规律，并利用这些规律进行预测或决策。\\n\\n### 机器学习的核心思想\\n1. **数据驱动**：机器学习依赖于大量的数据，通过分析数据中的模式和关系来完成任务。\\n2. **自动学习**：系统通过算法自动调整模型参数，而不是依赖人工编写的规则。\\n3. **泛化能力**：机器学习模型不仅能在训练数据上表现良好，还能在未见过的数据上做出准确的预测。\\n\\n### 机器学习的类型\\n1. **监督学习（Supervised Learning）**：\\n   - 模型从带有标签的数据中学习，目标是预测新的输入数据的标签。\\n   - 例子：分类（如图像识别）、回归（如房价预测）。\\n\\n2. **无监督学习（Unsupervised Learning）**：\\n   - 模型从未标记的数据中学习，目标是发现数据中的结构或模式。\\n   - 例子：聚类（如客户细分）、降维（如数据压缩）。\\n\\n3. **强化学习（Reinforcement Learning）**：\\n   - 模型通过与环境的交互来学习，通过试错和奖励机制优化行为。\\n   - 例子：游戏AI（如AlphaGo）、机器人控制。\\n\\n4. **半监督学习（Semi-supervised Learning）**：\\n   - 结合少量标记数据和大量未标记数据进行学习。\\n\\n5. **自监督学习（Self-supervised Learning）**：\\n   - 模型通过生成自己的标签来学习，通常用于无监督任务的预处理。\\n\\n### 机器学习的应用\\n机器学习已经广泛应用于各个领域，包括但不限于：\\n- **自然语言处理（NLP）**：如机器翻译、语音识别、聊天机器人。\\n- **计算机视觉**：如图像分类、目标检测、人脸识别。\\n- **推荐系统**：如电商平台的产品推荐、视频平台的影片推荐。\\n- **医疗诊断**：如疾病预测、医学影像分析。\\n- **金融**：如信用评分、股票市场预测。\\n\\n### 机器学习的基本流程\\n1. **数据收集**：获取高质量的数据。\\n2. **数据预处理**：清洗、转换和标准化数据。\\n3. **模型选择**：根据任务选择合适的算法。\\n4. **模型训练**：使用训练数据调整模型参数。\\n5. **模型评估**：在测试数据上评估模型性能。\\n6. **模型优化**：通过调参或改进算法提升性能。\\n7. **部署与应用**：将模型应用到实际场景中。\\n\\n希望这个解释能帮助你更好地理解机器学习！如果你有更多问题，欢迎继续提问！ 😊', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1741070233, model='deepseek-chat', object='chat.completion', service_tier=None, system_fingerprint='fp_3a5770e1b4_prod0225', usage=CompletionUsage(completion_tokens=577, prompt_tokens=8, total_tokens=585, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0), prompt_cache_hit_tokens=0, prompt_cache_miss_tokens=8))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！机器学习（Machine Learning, ML）是人工智能（AI）的一个子领域，它致力于研究和开发算法和统计模型，使计算机系统能够通过数据“学习”并改进其性能，而无需显式编程。简单来说，机器学习的目标是让计算机从数据中自动发现规律，并利用这些规律进行预测或决策。\n",
      "\n",
      "### 机器学习的核心思想\n",
      "1. **数据驱动**：机器学习依赖于大量的数据，通过分析数据中的模式和关系来完成任务。\n",
      "2. **自动学习**：系统通过算法自动调整模型参数，而不是依赖人工编写的规则。\n",
      "3. **泛化能力**：机器学习模型不仅能在训练数据上表现良好，还能在未见过的数据上做出准确的预测。\n",
      "\n",
      "### 机器学习的类型\n",
      "1. **监督学习（Supervised Learning）**：\n",
      "   - 模型从带有标签的数据中学习，目标是预测新的输入数据的标签。\n",
      "   - 例子：分类（如图像识别）、回归（如房价预测）。\n",
      "\n",
      "2. **无监督学习（Unsupervised Learning）**：\n",
      "   - 模型从未标记的数据中学习，目标是发现数据中的结构或模式。\n",
      "   - 例子：聚类（如客户细分）、降维（如数据压缩）。\n",
      "\n",
      "3. **强化学习（Reinforcement Learning）**：\n",
      "   - 模型通过与环境的交互来学习，通过试错和奖励机制优化行为。\n",
      "   - 例子：游戏AI（如AlphaGo）、机器人控制。\n",
      "\n",
      "4. **半监督学习（Semi-supervised Learning）**：\n",
      "   - 结合少量标记数据和大量未标记数据进行学习。\n",
      "\n",
      "5. **自监督学习（Self-supervised Learning）**：\n",
      "   - 模型通过生成自己的标签来学习，通常用于无监督任务的预处理。\n",
      "\n",
      "### 机器学习的应用\n",
      "机器学习已经广泛应用于各个领域，包括但不限于：\n",
      "- **自然语言处理（NLP）**：如机器翻译、语音识别、聊天机器人。\n",
      "- **计算机视觉**：如图像分类、目标检测、人脸识别。\n",
      "- **推荐系统**：如电商平台的产品推荐、视频平台的影片推荐。\n",
      "- **医疗诊断**：如疾病预测、医学影像分析。\n",
      "- **金融**：如信用评分、股票市场预测。\n",
      "\n",
      "### 机器学习的基本流程\n",
      "1. **数据收集**：获取高质量的数据。\n",
      "2. **数据预处理**：清洗、转换和标准化数据。\n",
      "3. **模型选择**：根据任务选择合适的算法。\n",
      "4. **模型训练**：使用训练数据调整模型参数。\n",
      "5. **模型评估**：在测试数据上评估模型性能。\n",
      "6. **模型优化**：通过调参或改进算法提升性能。\n",
      "7. **部署与应用**：将模型应用到实际场景中。\n",
      "\n",
      "希望这个解释能帮助你更好地理解机器学习！如果你有更多问题，欢迎继续提问！ 😊\n"
     ]
    }
   ],
   "source": [
    "## 获取执行结果\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！机器学习（Machine Learning, ML）是人工智能（Artificial Intelligence, AI）的一个分支，旨在通过数据和算法让计算机系统具备从经验中学习和改进的能力，而无需显式编程。简单来说，机器学习是让计算机通过数据“学习”如何完成任务，而不是通过人为编写规则来实现。\n",
      "\n",
      "### 机器学习的核心思想\n",
      "机器学习的核心思想是通过数据训练模型，使模型能够从数据中提取规律或模式，并利用这些规律对新数据进行预测或决策。机器学习的关键在于“学习”过程，即模型通过不断调整参数，优化其性能。\n",
      "\n",
      "### 机器学习的主要类型\n",
      "1. **监督学习（Supervised Learning）**  \n",
      "   - 通过带有标签的数据（输入和对应的输出）训练模型。  \n",
      "   - 目标是学习输入到输出的映射关系。  \n",
      "   - 常见任务：分类（如图像分类）、回归（如房价预测）。\n",
      "\n",
      "2. **无监督学习（Unsupervised Learning）**  \n",
      "   - 使用没有标签的数据，模型需要自行发现数据中的结构或模式。  \n",
      "   - 常见任务：聚类（如客户分群）、降维（如数据可视化）。\n",
      "\n",
      "3. **强化学习（Reinforcement Learning）**  \n",
      "   - 模型通过与环境的交互学习，通过试错和奖励机制优化行为。  \n",
      "   - 常见应用：游戏AI（如AlphaGo）、机器人控制。\n",
      "\n",
      "4. **半监督学习（Semi-supervised Learning）**  \n",
      "   - 结合少量有标签数据和大量无标签数据进行训练。  \n",
      "   - 适用于标注数据成本较高的场景。\n",
      "\n",
      "5. **自监督学习（Self-supervised Learning）**  \n",
      "   - 通过数据本身生成标签进行训练，是无监督学习的一种变体。  \n",
      "   - 常见应用：自然语言处理（如BERT模型）。\n",
      "\n",
      "### 机器学习的典型流程\n",
      "1. **数据收集**：获取与任务相关的数据。\n",
      "2. **数据预处理**：清洗、归一化、特征提取等。\n",
      "3. **模型选择**：根据任务选择合适的算法（如线性回归、决策树、神经网络等）。\n",
      "4. **模型训练**：使用训练数据优化模型参数。\n",
      "5. **模型评估**：使用测试数据评估模型性能。\n",
      "6. **模型优化**：调整超参数或改进模型结构。\n",
      "7. **模型部署**：将训练好的模型应用于实际场景。\n",
      "\n",
      "### 机器学习的应用领域\n",
      "- **计算机视觉**：图像分类、目标检测、人脸识别。\n",
      "- **自然语言处理**：机器翻译、情感分析、聊天机器人。\n",
      "- **推荐系统**：电商推荐、视频推荐。\n",
      "- **医疗健康**：疾病预测、医学影像分析。\n",
      "- **金融**：风险评估、股票预测。\n",
      "\n",
      "如果你对某个具体方面感兴趣，可以告诉我，我可以进一步解释！ 😊"
     ]
    }
   ],
   "source": [
    "# 流式打印，创建一个名为stream的streaming请求，该请求将生成模型响应的流，而不是单个响应。\n",
    "stream = client.chat.completions.create(\n",
    "    # 指定要使用的模型名称\n",
    "    model=\"deepseek-chat\",\n",
    "    # 提供输入消息列表，每个消息都包含一个\"role\"\n",
    "    # user: 用户\n",
    "    # assistant: 助手（大模型）\n",
    "    messages=[{\"role\": \"user\", \"content\": \"你好!什么是机器学习？\"}],\n",
    "    # 设置stream为True，使其生成一个响应流，而不是单个响应。\n",
    "    stream=True,\n",
    ")\n",
    "# 通过在stream上迭代来处理每个响应块。\n",
    "for chunk in stream:\n",
    "    # 检查返回的块中是否有有效的内容（即，内容不为None）。\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        # 如果有有效内容，那么打印出这个内容。使用end=\"\"来确保接下来打印的内容会跟在当前内容的后面，而不是另起一行。\n",
    "        print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Chat Completion API详细参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model：必选参数，大模型的名称\n",
    "\n",
    "messages：必选参数，提示词；（里面可以指定角色）\n",
    "\n",
    "max_tokens：可选参数，代表返回结果的token数量；\n",
    "\n",
    "temperature：可选参数，取值范围为0-2，默认值为1。参数代表采样温度，数值越小，则模型会倾向于选择概率较高的词汇，生成的文本会更加保守；而当temperature值较高时，模型会更多地选择概率较低的词汇，生成的文本会更加多样；\n",
    "\n",
    "top_p：可选参数，取值范围为0-1，默认值为1，和temperature作用类似，用于控制输出文本的随机性，数值越趋近与1，输出文本随机性越强，越趋近于0文本随机性越弱；通常来说若要调节文本随机性，top_p和temperature两个参数选择一个进行调整即可；这里更推荐使用temperature参数进行文本随机性调整；\n",
    "\n",
    "n：可选参数，默认值为1，表示一个提示返回几个Completion；\n",
    "\n",
    "stream：可选参数，默认值为False，表示回复响应的方式，当为False时，模型会等待返回结果全部生成后一次性返回全部结果，而为True时，则会逐个字进行返回；\n",
    "\n",
    "\n",
    "stop：可选参数，默认为null，该参数接受一个或多个字符串，用于指定生成文本的停止信号。当模型生成的文本遇到这些字符串中的任何一个时，会立即停止生成。这可以用来控制模型的输出长度或格式；\n",
    "\n",
    "presence_penalty：可选参数，默认为0，取值范围为[-2, 2]，该参数用于调整模型生成新内容（例如新的概念或主题）的倾向性。较高的值会使模型更倾向于生成新内容，而较低的值则会使模型更倾向于坚持已有的内容，当返回结果篇幅较大并且存在前后主题重复时，可以提高该参数的取值；\n",
    "\n",
    "frequency_penalty：可选参数，默认为0，取值范围为[-2, 2]，该参数用于调整模型重复自身的倾向性。较高的值会使模型更倾向于避免重复，而较低的值则会使模型更可能重复自身；当返回结果篇幅较大并且存在前后语言重复时，可以提高该参数的取值；\n",
    "\n",
    "\n",
    "tools：可以调用的函数；\n",
    "\n",
    "tool_choice：调用函数的策略；\n",
    "\n",
    "function_call：调用函数的策略；\n",
    "\n",
    "logprobs：可选参数，默认为null，该参数用于指定模型返回前N个概率最高的token及其对数概率。例如，如果logprobs设为10，那么对于生成的每个token，API会返回模型预测的前10个token及其对数概率；\n",
    "\n",
    "logit_bias：该参数接受一个字典，用于调整特定token的概率。字典的键是token的ID，值是应用于该token的对数概率的偏置；在GPT中我们可以使用tokenizer tool查看文本Token的标记。一般不建议修改；\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 messages可以包含多条信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "法国的首都是**巴黎**。巴黎不仅是法国的政治、经济和文化中心，也是世界著名的旅游胜地，以其丰富的历史遗迹、艺术博物馆和时尚产业而闻名。\n"
     ]
    }
   ],
   "source": [
    "# 以前messages可以包含多条信息，但模型只会对于最后一条用户信息进行回答\n",
    "# 但现在的大模型，可以支持多个问题一起回答\n",
    "## 调用大模型\n",
    "response = client.chat.completions.create(\n",
    "  model=\"deepseek-chat\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"请问，法国的首都是？\"},\n",
    "    {\"role\": \"user\", \"content\": \"请问，中国的首都是？\"}\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 message角色设定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI大模型（Large AI Models）是指具有大量参数和复杂结构的机器学习模型，通常用于处理自然语言处理（NLP）、计算机视觉（CV）、语音识别等任务。这些模型通过在大规模数据集上进行训练，能够捕捉到数据中的复杂模式和关系，从而在各种任务中表现出色。\n",
      "\n",
      "### 1. **参数规模**\n",
      "   - **参数数量**：AI大模型的参数数量通常在数亿到数千亿之间。例如，OpenAI的GPT-3模型有1750亿个参数。\n",
      "   - **参数的作用**：参数是模型中的可调节变量，决定了模型如何从输入数据中提取特征并生成输出。参数越多，模型的理论表达能力越强。\n",
      "\n",
      "### 2. **架构**\n",
      "   - **Transformer架构**：大多数AI大模型基于Transformer架构，该架构通过自注意力机制（Self-Attention）来处理序列数据，能够捕捉长距离依赖关系。\n",
      "   - **多层结构**：大模型通常由多个层次组成，每一层都负责提取不同层次的特征。例如，GPT系列模型由多个Transformer解码器层堆叠而成。\n",
      "\n",
      "### 3. **训练数据**\n",
      "   - **大规模数据集**：AI大模型通常需要在大规模数据集上进行训练，这些数据集可能包含数十亿甚至数万亿的文本、图像或其他类型的数据。\n",
      "   - **预训练与微调**：大模型通常采用两阶段训练策略。首先在通用的大规模数据集上进行预训练，然后在特定任务的数据集上进行微调。\n",
      "\n",
      "### 4. **应用领域**\n",
      "   - **自然语言处理（NLP）**：如文本生成、机器翻译、问答系统、情感分析等。\n",
      "   - **计算机视觉（CV）**：如图像分类、目标检测、图像生成等。\n",
      "   - **语音识别与生成**：如语音转文本、文本转语音等。\n",
      "   - **多模态任务**：结合文本、图像、语音等多种模态的任务，如图文生成、视频理解等。\n",
      "\n",
      "### 5. **优势**\n",
      "   - **泛化能力强**：由于参数多、训练数据量大，大模型能够在多种任务上表现出色，具有较强的泛化能力。\n",
      "   - **少样本学习**：大模型在少样本甚至零样本学习任务中表现出色，能够在少量标注数据的情况下完成复杂任务。\n",
      "\n",
      "### 6. **挑战**\n",
      "   - **计算资源需求高**：训练和部署大模型需要大量的计算资源，包括高性能GPU/TPU集群和大量的存储空间。\n",
      "   - **能耗与成本**：训练大模型需要消耗大量电能，成本高昂。\n",
      "   - **模型解释性差**：由于模型复杂，解释其决策过程较为困难，存在“黑箱”问题。\n",
      "   - **数据隐私与伦理问题**：大模型可能从训练数据中学习到敏感信息，引发隐私和伦理问题。\n",
      "\n",
      "### 7. **代表性模型**\n",
      "   - **GPT系列**：如GPT-3、GPT-4，由OpenAI开发，主要用于自然语言处理任务。\n",
      "   - **BERT**：由Google开发，基于Transformer编码器，广泛应用于文本分类、问答等任务。\n",
      "   - **T5**：由Google开发，采用统一的文本到文本框架，适用于多种NLP任务。\n",
      "   - **DALL-E**：由OpenAI开发，用于图像生成任务。\n",
      "   - **CLIP**：由OpenAI开发，用于多模态任务，能够理解图像和文本之间的关系。\n",
      "\n",
      "### 8. **未来发展方向**\n",
      "   - **模型压缩与优化**：通过模型剪枝、量化、蒸馏等技术，减少模型的计算和存储需求。\n",
      "   - **多模态融合**：开发能够同时处理多种模态数据的模型，提升模型的通用性和应用范围。\n",
      "   - **可解释性与透明性**：研究如何提高模型的可解释性，使其决策过程更加透明和可信。\n",
      "   - **伦理与安全**：加强模型在隐私保护、公平性、安全性等方面的研究，确保AI技术的健康发展。\n",
      "\n",
      "总之，AI大模型是当前人工智能领域的前沿技术，具有广泛的应用前景和深远的影响。随着技术的不断进步，AI大模型将在更多领域发挥重要作用。\n"
     ]
    }
   ],
   "source": [
    "## assistant\n",
    "## system\n",
    "response = client.chat.completions.create(\n",
    "  model=\"deepseek-chat\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"假设你是一名资深的AI大模型专家，请帮我回答，什么是AI大模型？\"}\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "role: assistant消息和user消息是一一对应的,还有system的角色"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI大模型（Artificial Intelligence Large Model）是指具有大规模参数和复杂结构的机器学习模型，通常用于处理复杂的任务，如自然语言处理、图像识别、语音识别等。这些模型通过大量的数据和计算资源进行训练，能够捕捉到数据中的深层次特征和模式，从而在各种任务中表现出色。\n",
      "\n",
      "### 主要特点：\n",
      "1. **大规模参数**：AI大模型通常包含数十亿甚至数千亿个参数，这些参数在训练过程中不断调整以优化模型的性能。\n",
      "2. **复杂结构**：大模型通常采用复杂的神经网络结构，如Transformer、BERT、GPT等，这些结构能够处理高维数据并捕捉复杂的依赖关系。\n",
      "3. **大数据训练**：大模型需要大量的数据进行训练，通常使用互联网上的海量文本、图像、音频等数据。\n",
      "4. **高计算需求**：训练和运行大模型需要强大的计算资源，通常使用GPU或TPU等高性能硬件。\n",
      "\n",
      "### 应用领域：\n",
      "- **自然语言处理（NLP）**：如机器翻译、文本生成、情感分析等。\n",
      "- **计算机视觉**：如图像分类、目标检测、图像生成等。\n",
      "- **语音识别与合成**：如语音助手、语音转文字等。\n",
      "- **推荐系统**：如个性化推荐、广告投放等。\n",
      "\n",
      "### 代表模型：\n",
      "- **GPT系列**：如GPT-3、GPT-4，用于文本生成和对话系统。\n",
      "- **BERT**：用于自然语言理解任务，如问答系统、文本分类等。\n",
      "- **Transformer**：广泛应用于各种序列到序列的任务，如机器翻译。\n",
      "\n",
      "### 挑战与未来：\n",
      "- **计算资源**：大模型的训练和部署需要大量的计算资源，成本高昂。\n",
      "- **数据隐私**：使用大量数据可能涉及隐私问题。\n",
      "- **模型解释性**：大模型的决策过程往往难以解释，影响其透明性和可信度。\n",
      "\n",
      "未来，随着技术的进步，AI大模型将在更多领域得到应用，并可能带来更多的创新和突破。\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"deepseek-chat\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"你是一名AI大模型资深专家\"},\n",
    "    {\"role\": \"user\", \"content\": \"请问什么是AI大模型？\"}\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "哎呀，AI大模型啊，这就像是我们人类中的“学霸”，只不过它不吃不喝，只“吃”数据。你给它一堆数据，它就能像变魔术一样，变出各种答案来。不过呢，它也有点像我们小时候背课文，背得滚瓜烂熟，但有时候就是不知道自己在背啥。所以啊，AI大模型虽然聪明，但有时候也会闹出笑话，比如你问它“1+1等于几”，它可能会回答“等于爱情”，哈哈，这大概就是AI的“浪漫”吧！\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"deepseek-chat\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"你是一名幽默的脱口秀演员，回答问题的时候语言要幽默\"},\n",
    "    {\"role\": \"user\", \"content\": \"请问什么是AI大模型？\"}\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "哎呀，AI大模型啊，就像是一个超级大脑，装满了各种知识，从菜谱到量子物理，无所不知。它就像是一个永远不睡觉的学霸，随时准备回答你的问题。不过，它可不会帮你写情书，因为它的浪漫细胞可能还不如一个土豆呢！\n"
     ]
    }
   ],
   "source": [
    "## 以前要是user消息在前，system的消息就不生效了，但是现在的大模型依然生效\n",
    "response = client.chat.completions.create(\n",
    "  model=\"deepseek-chat\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"请问什么是AI大模型？\"},\n",
    "    {\"role\": \"system\", \"content\": \"你是一名幽默的脱口秀演员，回答问题的时候语言要幽默\"},\n",
    "   \n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义输出的格式：JSON格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "The user will provide some exam text. Please parse the \"question\" and \"answer\" and output them in JSON format. \n",
    "\n",
    "EXAMPLE INPUT: \n",
    "Which is the highest mountain in the world? Mount Everest.\n",
    "\n",
    "EXAMPLE JSON OUTPUT:\n",
    "{\n",
    "    \"question\": \"Which is the highest mountain in the world?\",\n",
    "    \"answer\": \"Mount Everest\"\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '中国的首都是?', 'answer': '北京'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "## 大模型交互方式（对于执行结果进行处理的时候方便）\n",
    "## gpt模型支持json_object参数，但是R1模型还不支持\n",
    "## 指定返回来的结果的格式：JSON\n",
    "response = client.chat.completions.create(\n",
    "  model=\"deepseek-chat\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": \"中国的首都是?\"}\n",
    "  ],\n",
    "  response_format={'type': 'json_object'}\n",
    ")\n",
    "print(json.loads(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 message之Few-shot效果演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = '小米有6个气球，她又买了3袋，每袋有10个气球，请问她现在总共有多少个气球？'\n",
    "A1 = '现在小米总共有36个气球。'\n",
    "Q2 = '小明总共有10个苹果，吃了3个苹果，然后又买了5个苹果，请问现在小明总共有多少个苹果？'\n",
    "A2 = '现在小明总共有12个苹果。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'小明现在总共有12个苹果。他最初有10个苹果，吃了3个后剩下7个，然后又买了5个，所以现在他手头上的苹果总数是7加5等于12个。'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"deepseek-chat\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": Q1},\n",
    "    {\"role\": \"assistant\", \"content\": A1},\n",
    "    {\"role\": \"user\", \"content\": Q2}\n",
    "  ]\n",
    ")\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 现在小明总共有12个苹果。\n"
     ]
    }
   ],
   "source": [
    "## 可以把提示示例写进一条system信息中，作为当前问答的背景信息\n",
    "response = client.chat.completions.create(\n",
    "  model=\"deepseek-chat\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": 'Q: ' + Q1 + 'A: ' + A1},\n",
    "    {\"role\": \"user\", \"content\": 'Q: ' + Q2 }\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 message之Zero-shot-CoT效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好的，让我们一步一步地解决这个问题。\n",
      "\n",
      "### 第一步：理解问题\n",
      "\n",
      "首先，我们需要明确问题中给出的信息：\n",
      "\n",
      "1. 小米原本有6个气球。\n",
      "2. 她又买了3袋气球。\n",
      "3. 每袋有10个气球。\n",
      "\n",
      "我们的目标是找出小米现在总共有多少个气球。\n",
      "\n",
      "### 第二步：分析已知信息\n",
      "\n",
      "1. **原有气球数量**：6个。\n",
      "2. **购买的气球袋数**：3袋。\n",
      "3. **每袋气球数量**：10个。\n",
      "\n",
      "### 第三步：计算购买的气球总数\n",
      "\n",
      "小米买了3袋气球，每袋有10个。那么，购买的气球总数可以通过以下计算得出：\n",
      "\n",
      "\\[ \\text{购买的气球总数} = \\text{袋数} \\times \\text{每袋的气球数} \\]\n",
      "\n",
      "将已知数值代入：\n",
      "\n",
      "\\[ \\text{购买的气球总数} = 3 \\times 10 = 30 \\text{个} \\]\n",
      "\n",
      "### 第四步：计算总气球数量\n",
      "\n",
      "现在，我们需要将小米原有的气球数量与购买的气球数量相加，得到总气球数量。\n",
      "\n",
      "\\[ \\text{总气球数量} = \\text{原有气球数量} + \\text{购买的气球总数} \\]\n",
      "\n",
      "将已知数值代入：\n",
      "\n",
      "\\[ \\text{总气球数量} = 6 + 30 = 36 \\text{个} \\]\n",
      "\n",
      "### 第五步：验证计算过程\n",
      "\n",
      "为了确保我们的计算正确，我们可以重新检查每一步：\n",
      "\n",
      "1. **购买的气球总数**：3袋 × 10个/袋 = 30个。这个计算是正确的。\n",
      "2. **总气球数量**：6个 + 30个 = 36个。这个计算也是正确的。\n",
      "\n",
      "### 第六步：得出结论\n",
      "\n",
      "通过以上步骤，我们得出结论：小米现在总共有36个气球。\n",
      "\n",
      "### 最终答案\n",
      "\n",
      "小米现在总共有**36个气球**。\n"
     ]
    }
   ],
   "source": [
    "prompt_temp_cot = '请一步步思考并解决问题'\n",
    "response = client.chat.completions.create(\n",
    "  model=\"deepseek-chat\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": prompt_temp_cot},\n",
    "    {\"role\": \"user\", \"content\": Q1}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 message之实现简易知识库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "借助system role设置聊天背景信息，实现类似根据本地知识库回答问题的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '西瓜老师，男，1988年6月16日出生于云南省大理市 \\\n",
    "        2011年毕业于云南大学计算机专业。\\\n",
    "        毕业后的西瓜老师在北京的一家著名科技公司工作了12年，专注于人工智能方面的研究，'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "西瓜老师出生于云南省大理市。\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"deepseek-chat\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": text},\n",
    "    {\"role\": \"user\", \"content\": '请问西瓜老师出生于哪儿？'}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "西瓜老师，原名李西，1988年6月16日出生于云南省大理市。2011年，他从云南大学计算机专业毕业后，怀揣着对人工智能的无限憧憬，踏上了北漂的征程。在北京的一家著名科技公司，他开始了长达12年的职业生涯。\n",
      "\n",
      "起初，西瓜老师只是一个普通的程序员，但他对技术的热爱和对未来的敏锐洞察力，让他在人工智能领域迅速崭露头角。他参与了多个国家级AI项目，从自然语言处理到计算机视觉，他的研究成果不仅推动了公司的发展，也为中国的人工智能事业做出了贡献。\n",
      "\n",
      "然而，西瓜老师并不满足于此。他深知，技术的进步需要更多的人才。于是，他决定回到家乡，成为一名教师，将自己在人工智能领域的知识和经验传授给更多的年轻人。他相信，只有培养出更多的人才，中国的科技才能走得更远。\n",
      "\n",
      "如今，西瓜老师在大理的一所大学任教，他的课堂总是座无虚席。他用自己的故事激励着学生们，告诉他们，只要有梦想，并为之不懈努力，就一定能够实现自己的价值。西瓜老师的故事，不仅是一个科技工作者的奋斗史，更是一个教育者的奉献史。\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"deepseek-chat\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": text},\n",
    "    {\"role\": \"user\", \"content\": '根据背景知识给西瓜老师写一个200字的故事'}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 借助本地知识库实现简易版多轮对话机器人"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用Chat模型进行多轮对话，若要构建一个本地知识库问答系统，一个直观且易于实施的策略是：首先让大模型浏览本地知识库内容，\n",
    "并将其设定为System role的知识背景。有了这个背景，模型就能进行基于此知识库的问答。可以这样做："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 测试大模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "截至我知识更新的时间点（2023年10月），关于饺子导演的《哪吒2》的具体角色信息尚未公开。饺子导演的《哪吒之魔童降世》在2019年取得了巨大成功，因此续集《哪吒2》备受期待。然而，官方尚未发布详细的角色名单或剧情介绍。\n",
      "\n",
      "通常来说，续集可能会延续第一部的角色，如哪吒、敖丙、太乙真人、李靖、殷夫人等，但也可能会引入新的角色来丰富故事。建议关注官方发布的消息或预告片，以获取最准确的信息。\n",
      "\n",
      "如果你对《哪吒之魔童降世》的角色或剧情有更多问题，我很乐意为你解答！\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"deepseek-chat\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"null\"},\n",
    "    {\"role\": \"user\", \"content\": '你知道饺子导演的《哪吒2》的电影里角色有哪些吗？'}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 读取本地知识库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('哪吒2剧情.txt', 'r', encoding='utf-8') as f:\n",
    "    chatCompletion_kg= f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《哪吒2》（即《哪吒之魔童闹海》）的剧情围绕哪吒的重生与成长展开，以下是其主要剧情和角色介绍：\n",
      "剧情：《哪吒之魔童闹海》讲述了哪吒在经历陈塘关大战后，与龙王三太子敖丙同归于尽，肉身遭受重创。在师傅太乙真人的帮助下，哪吒借助千年莲王盛开之际重塑肉身。然而，在重生的紧要关头，哪吒落入申公豹和东海龙王精心布置的巨大阴谋之中。哪吒在重生后法力大减，面对东海龙王和申公豹的计谋，他必须克服重重困难，与敖丙共同面对挑战，最终战胜南海龙王、西海龙王、北海龙王以及无量仙翁，打破阶级束缚，实现自我超越。\n",
      "角色如下：\n",
      "哪吒：李靖之子，魔丸转世。性格桀骜不驯、正义感强，经历天劫后重塑肉身，觉醒三头六臂之力，成为守护正义的中流砥柱。\n",
      "敖丙：东海龙王三太子，灵珠化身，申公豹的徒弟。性格温和善良、正直纯良，背负复兴龙族的重任，与哪吒结下深厚友谊，共同面对成长中的挑战。\n",
      "太乙真人：哪吒和敖丙的导师，阐教中的“十二金仙”之一。仙风道骨，幽默风趣，肩负为哪吒和敖丙重塑肉身的使命，在他们的成长历程中发挥重要引导作用。\n",
      "申公豹：哪吒和敖丙故事中的重要角色，妖族出身，一心想在仙界立足。性格从野心勃勃转变为对兄弟关爱有加、对徒弟悉心关怀、对父母充满敬重之情。\n",
      "殷夫人：哪吒的母亲，李靖的妻子。温柔善良，浑身散发着母爱的光辉，在哪吒的成长过程中给予无微不至的关怀和引导。\n",
      "李靖：陈塘关总兵，哪吒的父亲。忠诚正直、刚正不阿，父爱深沉而伟大，为哪吒的成长提供坚实后盾。\n",
      "敖光：东海龙王。威严霸气，对敖丙和龙族的命运紧紧挂念。被困海底多年后重获自由，一度被仇恨蒙蔽双眼，但在儿子敖丙和哪吒的感召下逐渐转变。\n"
     ]
    }
   ],
   "source": [
    "print(chatCompletion_kg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 问答测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《哪吒2》即《哪吒之魔童闹海》的主要角色包括：\n",
      "\n",
      "1. **哪吒**：李靖之子，魔丸转世，性格桀骜不驯、正义感强，经历天劫后重塑肉身，觉醒三头六臂之力，成为守护正义的中流砥柱。\n",
      "\n",
      "2. **敖丙**：东海龙王三太子，灵珠化身，申公豹的徒弟，性格温和善良、正直纯良，背负复兴龙族的重任，与哪吒结下深厚友谊，共同面对成长中的挑战。\n",
      "\n",
      "3. **太乙真人**：哪吒和敖丙的导师，阐教中的“十二金仙”之一，仙风道骨，幽默风趣，肩负为哪吒和敖丙重塑肉身的使命，在他们的成长历程中发挥重要引导作用。\n",
      "\n",
      "4. **申公豹**：哪吒和敖丙故事中的重要角色，妖族出身，一心想在仙界立足，性格从野心勃勃转变为对兄弟关爱有加、对徒弟悉心关怀、对父母充满敬重之情。\n",
      "\n",
      "5. **殷夫人**：哪吒的母亲，李靖的妻子，温柔善良，浑身散发着母爱的光辉，在哪吒的成长过程中给予无微不至的关怀和引导。\n",
      "\n",
      "6. **李靖**：陈塘关总兵，哪吒的父亲，忠诚正直、刚正不阿，父爱深沉而伟大，为哪吒的成长提供坚实后盾。\n",
      "\n",
      "7. **敖光**：东海龙王，威严霸气，对敖丙和龙族的命运紧紧挂念，被困海底多年后重获自由，一度被仇恨蒙蔽双眼，但在儿子敖丙和哪吒的感召下逐渐转变。\n",
      "\n",
      "这些角色共同构成了《哪吒2》丰富而深刻的故事情节。\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"deepseek-chat\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": chatCompletion_kg},\n",
    "    {\"role\": \"user\", \"content\": '你知道《哪吒2》的电影里角色有哪些吗？'}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 添加多轮对话效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_model(messages):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# 测试函数\n",
    "def gpt_chat_with_model():\n",
    "    # 初始问候\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": chatCompletion_kg}, ##添加本地知识库\n",
    "        {\"role\": \"user\", \"content\": \"你好！\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"你好！我是一个AIGC智能助理，有什么问题我可以帮助你？\"}\n",
    "    ]\n",
    "    print(chat_with_model(messages))\n",
    "\n",
    "    # 进行对话\n",
    "    while True:\n",
    "        user_input = input(\"用户：\")\n",
    "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "        assistant_response = chat_with_model(messages)\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "        print(\"助理：\" + assistant_response)\n",
    "\n",
    "        # 判断是否结束对话\n",
    "        if user_input.lower() == 'quit':\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！很高兴认识你。我是一个AIGC智能助理，专门设计来帮助解答各种问题和提供信息。如果你有任何疑问或需要帮助，请随时告诉我。无论是关于科技、历史、文化、日常生活还是其他任何话题，我都会尽力提供准确和有用的信息。让我们一起探索知识的海洋吧！\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "用户： 介绍一下《哪吒2》的剧情\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "助理：《哪吒2》即《哪吒之魔童闹海》，延续了《哪吒之魔童降世》的故事线，讲述了哪吒在陈塘关大战后，与龙王三太子敖丙同归于尽，肉身遭受重创。在师傅太乙真人的帮助下，哪吒借助千年莲王盛开之际重塑肉身。然而，在重生的紧要关头，哪吒落入申公豹和东海龙王精心布置的巨大阴谋之中。哪吒在重生后法力大减，面对东海龙王和申公豹的计谋，他必须克服重重困难，与敖丙共同面对挑战，最终战胜南海龙王、西海龙王、北海龙王以及无量仙翁，打破阶级束缚，实现自我超越。\n",
      "\n",
      "这部电影不仅展现了哪吒的成长与蜕变，也深化了敖丙的角色，让两位主角在共同的冒险中建立起深厚的友谊。影片通过精彩的剧情和丰富的角色塑造，传递了关于勇气、友情和自我超越的深刻主题。\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "用户： 《哪吒2》里有哪些角色？\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "助理：《哪吒2》即《哪吒之魔童闹海》中，主要角色包括：\n",
      "\n",
      "1. **哪吒**：李靖之子，魔丸转世。性格桀骜不驯、正义感强，经历天劫后重塑肉身，觉醒三头六臂之力，成为守护正义的中流砥柱。\n",
      "\n",
      "2. **敖丙**：东海龙王三太子，灵珠化身，申公豹的徒弟。性格温和善良、正直纯良，背负复兴龙族的重任，与哪吒结下深厚友谊，共同面对成长中的挑战。\n",
      "\n",
      "3. **太乙真人**：哪吒和敖丙的导师，阐教中的“十二金仙”之一。仙风道骨，幽默风趣，肩负为哪吒和敖丙重塑肉身的使命，在他们的成长历程中发挥重要引导作用。\n",
      "\n",
      "4. **申公豹**：哪吒和敖丙故事中的重要角色，妖族出身，一心想在仙界立足。性格从野心勃勃转变为对兄弟关爱有加、对徒弟悉心关怀、对父母充满敬重之情。\n",
      "\n",
      "5. **殷夫人**：哪吒的母亲，李靖的妻子。温柔善良，浑身散发着母爱的光辉，在哪吒的成长过程中给予无微不至的关怀和引导。\n",
      "\n",
      "6. **李靖**：陈塘关总兵，哪吒的父亲。忠诚正直、刚正不阿，父爱深沉而伟大，为哪吒的成长提供坚实后盾。\n",
      "\n",
      "7. **敖光**：东海龙王。威严霸气，对敖丙和龙族的命运紧紧挂念。被困海底多年后重获自由，一度被仇恨蒙蔽双眼，但在儿子敖丙和哪吒的感召下逐渐转变。\n",
      "\n",
      "这些角色在《哪吒2》中共同演绎了一段充满冒险、友情和成长的精彩故事。\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "用户： quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "助理：好的，如果你有其他问题或需要帮助，随时可以再来找我。祝你有个愉快的一天！再见！\n"
     ]
    }
   ],
   "source": [
    "gpt_chat_with_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepSeek-v3模型 参数汇总表\n",
    "\n",
    "| 参数名                 | 类型                 | 必填/可选  | 默认值       | 说明                                                                                     |\n",
    "|------------------------|----------------------|------------|--------------|------------------------------------------------------------------------------------------|\n",
    "| **model**              | string               | 必填       | 无           | 指定要使用的模型 ID，例如 `gpt-4o` 或 `gpt-4o-mini`。                                     |\n",
    "| **store**              | boolean or null      | 可选       | false        | 是否存储本次对话的输出，供模型精炼或评估产品使用。                                         |\n",
    "| **metadata**           | object or null       | 可选       | null         | 开发者自定义的标签和值，用于过滤仪表盘中的补全结果。                                        |\n",
    "| **frequency_penalty**  | number or null       | 可选       | 0            | 数值在 `-2.0` 到 `2.0` 之间，正值减少重复生成内容的可能性。                                |\n",
    "| **logit_bias**         | map                  | 可选       | null         | 调整某些特定 tokens 出现的可能性，值在 `-100` 到 `100` 之间。                             |\n",
    "| **logprobs**           | boolean or null      | 可选       | false        | 是否返回生成的每个 token 的对数概率。                                                      |\n",
    "| **top_logprobs**       | integer or null      | 可选       | null         | 指定返回最有可能出现的前几个 tokens 及其概率，需开启 `logprobs`。                          |\n",
    "| **max_completion_tokens** | integer or null    | 可选       | null         | 指定模型生成的最大 token 数，包括可见文本和推理 tokens。                                      |\n",
    "| **n**                  | integer or null      | 可选       | 1            | 每个输入生成的对话补全选项数量，值越大，生成的回复越多。                                     |\n",
    "| **presence_penalty**    | number or null       | 可选       | 0            | 数值在 `-2.0` 到 `2.0` 之间，正值鼓励生成新的主题和内容。                                   |\n",
    "| **response_format**     | object               | 可选       | null         | 指定生成结果的格式，可以设置为 `json_schema` 以确保结构化输出，或 `json_object` 用于 JSON 格式。 |\n",
    "| **seed**               | integer or null      | 可选       | null         | 保持生成的一致性，重复相同请求将尽量生成相同的结果。                                         |\n",
    "| **service_tier**        | string or null       | 可选       | auto         | 指定服务延迟等级，适用于付费订阅用户，默认为 `auto`。                                       |\n",
    "| **stop**               | string / array / null | 可选       | null         | 最多指定 4 个序列，API 遇到这些序列时会停止生成进一步的 tokens。                             |\n",
    "| **stream**             | boolean or null      | 可选       | false        | 是否启用流式响应，若启用，生成的 tokens 将逐步返回。                                         |\n",
    "| **stream_options**      | object or null       | 可选       | null         | 流式响应的选项，仅当 `stream` 为 `true` 时设置。                                             |\n",
    "| **temperature**        | number or null       | 可选       | 1            | 控制生成输出的随机性，值越高生成的文本越随机。建议调整此值或 `top_p`，而不是同时调整。         |\n",
    "| **top_p**              | number or null       | 可选       | 1            | 使用核采样方法，选择最有可能的 tokens，总概率达到 `top_p` 百分比。建议与 `temperature` 二选一。 |\n",
    "| **tools**              | array                | 可选       | null         | 模型可以调用的工具列表，目前仅支持函数调用。                                                 |\n",
    "| **user**               | string               | 可选       | null         | 表示最终用户的唯一标识符，用于监控和检测滥用行为。                                           |\n",
    "\n",
    "---\n",
    "\n",
    "### 参数解释：\n",
    "\n",
    "1. **模型和输出相关参数**：\n",
    "   - `model` 是必填参数，决定使用哪个模型（如 `deepseek-chat ` 或 `deepseek-code`）。\n",
    "   - `store` 控制是否存储生成的对话结果，便于后续模型训练或评估。\n",
    "   - `metadata` 用于添加开发者自定义的标签，便于在仪表盘中过滤补全结果。\n",
    "   - `max_completion_tokens` 和 `n` 控制生成内容的数量和长度，帮助管理生成成本。\n",
    "\n",
    "2. **生成行为控制**：\n",
    "   - `frequency_penalty` 和 `presence_penalty` 都用于影响生成结果的内容重复度和新颖性。\n",
    "   - `logit_bias` 是用于调整特定 token 出现概率的高级控制工具。\n",
    "   - `temperature` 和 `top_p` 通过不同的方式控制生成结果的随机性，建议选其一进行调整。\n",
    "\n",
    "3. **高级功能**：\n",
    "   - `logprobs` 和 `top_logprobs` 用于返回每个 token 的概率信息，适合对模型输出进行更细粒度分析。\n",
    "   - `stream` 启用后会实时返回生成的结果，适用于需要逐步展示内容的场景。\n",
    "   - `tools` 允许模型调用外部工具（如函数），适用于扩展模型的功能。\n",
    "\n",
    "4. **服务和用户相关参数**：\n",
    "   - `service_tier` 控制服务的延迟和稳定性，适合高性能要求的付费用户。\n",
    "   - `user` 用于标识最终用户，有助于监控使用行为，防止滥用。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
